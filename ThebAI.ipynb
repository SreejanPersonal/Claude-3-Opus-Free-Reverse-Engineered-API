{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude-3-Opus-Free-Reverse-Engineered-API\n",
    "======================================\n",
    "Author: Devs Do Code (Sree)\n",
    "\n",
    "Description: Free and unlimited API interface to Claude 3 Opus and other AI models.\n",
    "\n",
    "Features: Free and unlimited, Reverse-engineered, 10+ AI models available, including Claude 3 Opus\n",
    "\n",
    "License: MIT License\n",
    "\n",
    "Contributing: Fork and submit a pull request to contribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def load_api_info():\n",
    "    with open(\"Theb_API.json\", \"r\") as file:\n",
    "        return json.load(file)\n",
    "    \n",
    "def remove_apis():\n",
    "    with open(\"Theb_API.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    if data: data.pop(0)\n",
    "    with open(\"Theb_API.json\", \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "def initiate_api_conversation(input_text: str, model_identifier: str = 'Claude-3-Opus', organization_id: str = load_api_info()[0]['ORGANIZATION_ID'], access_token: str = load_api_info()[0]['API_KEY']) -> str:\n",
    "    \"\"\"\n",
    "    Initiates an API conversation request and retrieves the response content.\n",
    "\n",
    "    Parameters:\n",
    "    - organization_id (str): The unique identifier for the API organization.\n",
    "    - model_identifier (str): The identifier for the desired conversation model.\n",
    "    - input_text (str): The textual input for initiating the conversation.\n",
    "\n",
    "    Returns:\n",
    "    - str: The textual content of the API response.\n",
    "\n",
    "    Note:\n",
    "    - The model_identifier should correspond to one of the predefined model keys.\n",
    "    \"\"\"\n",
    "\n",
    "    # Mapping of model identifiers to their respective keys\n",
    "    model_key_mapping = {\n",
    "        'Claude-3-Opus' : 'ade084104e614c31ada6892744fcd3c5',\n",
    "        'Claude-3-Haiku' : \"d2c2b37c042d4b248af62a033eccd1b2\",\n",
    "        'Claude-3-Sonnet' : \"8b851ff081d54ba7b46a42a5099fcc64\",\n",
    "        'Claude 2': 'a248a40fe3c4493598064c9ba725e8c9',\n",
    "\n",
    "        'llama-3-70b': '5da08fc7ac704d0d9bee545cbbb91793',\n",
    "        'llama-3-8b': 'c60d009ce85f47f087952f17eead4eab',\n",
    "        'cod-llama-70b': 'bccdb1b4dee94dc59d6e15e2a73ac2ba',\n",
    "\n",
    "        'mistral 8x22b': '70b3f32d71a34b97af9d660e1245fe15',\n",
    "        'WizardLM 2 8x22B' : 'ebf8820be60f40a38a3cae32795f8bd2',\n",
    "\n",
    "        'chatgpt-3-5-turbo': '58f5e7e50fee4779a1e5fe16c3aa302b',\n",
    "        'dbrx': '20ea474d42dd44eaa618971cdb16bfa7',\n",
    "        'Theb-ai': '7e682da4dde7ee214baa0efc0cf6d7a4',\n",
    "        \n",
    "    }\n",
    "\n",
    "    # API endpoint construction\n",
    "    api_endpoint = f\"https://beta.theb.ai/api/conversation?org_id={organization_id}&req_rand={random.random()}\"\n",
    "\n",
    "    # HTTP request headers\n",
    "    request_headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "    }\n",
    "\n",
    "    # HTTP request payload\n",
    "    request_payload = {\n",
    "        \"text\": input_text,\n",
    "        \"model\": model_key_mapping[model_identifier],\n",
    "        \"functions\": None,\n",
    "        \"attachments\": [],\n",
    "        \"model_params\": {\n",
    "            \"system_prompt\": \"Be Helpful and Friendly\",\n",
    "            \"temperature\": \"1\",\n",
    "            \"top_p\": \"1\",\n",
    "            \"frequency_penalty\": \"0\",\n",
    "            \"presence_penalty\": \"0\",\n",
    "            \"long_term_memory\": \"ltm\"\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Execution of the API request\n",
    "    payload_as_json = json.dumps(request_payload)\n",
    "    response = requests.post(api_endpoint, headers=request_headers, data=payload_as_json, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        accumulated_response_text = \"\"\n",
    "        for line in response.iter_lines(decode_unicode=True, chunk_size=1, delimiter=\"\\n\"):\n",
    "            if line and \"event: \" not in line:\n",
    "                line_content = re.sub(\"data:\", \"\", line)\n",
    "                try:\n",
    "                    response_data = json.loads(line_content)\n",
    "                    if 'tid' in response_data: continue\n",
    "                    print(response_data['args']['content'].replace(accumulated_response_text, ''), end=\"\")\n",
    "                    accumulated_response_text = response_data['args']['content']\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "\n",
    "        \n",
    "        if accumulated_response_text != \"\": return accumulated_response_text\n",
    "        else : \n",
    "            resp_lines = response.text.split(\"\\r\")\n",
    "            for line in reversed(resp_lines):\n",
    "                if \"event: \" not in line and line.strip():\n",
    "                    try:\n",
    "                        data_value = re.sub(\"data:\", \"\", line)\n",
    "                        json_data = json.loads(data_value)\n",
    "                        return json_data['args']['content']\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "            \n",
    "    elif response.status_code == 400:\n",
    "        print(\"\\033[91m\" + f\"Switching to Next API \" + \"\\033[0m\")\n",
    "        remove_apis()\n",
    "        return initiate_api_conversation(input_text=input_text, model_identifier=model_identifier, organization_id= load_api_info()[0]['ORGANIZATION_ID'], access_token = load_api_info()[0]['API_KEY'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"\\033[91mIt is worth noting that, when running in a Jupyter notebook environment, the code output may appear to be faster compared to a regular Python script. This discrepancy in performance has not been fully understood, but it is possible that contributing to resolving this issue could be beneficial. Additionally, the website that has been reverse engineered for this API interaction has been observed to be slow in terms of response time. Therefore, it is to be expected that the API responses will also be slower in comparison. It is suggested to use smaller models, such as 'llama-3-8b', to improve the responsiveness of the API interaction. Furthermore, it should be noted that the underlying website does not support fast API inference, resulting in slower responses\\n\\n\\033[92m1This will be printed on every command. It is recommended that you remove this print statement for not getting irritated\\033[0m\")\n",
    "    \n",
    "    response_content = initiate_api_conversation(input_text=\"Write 30 Lines about India \")\n",
    "    # response_content = initiate_api_conversation(input_text=\"Can you please provide information about your development team, including the company or organization that created you, the names of your creators or lead developers, the programming languages and frameworks used to build you, and any notable features or technologies that enable your conversational capabilities?\", model_identifier=\"Claude-3-Sonnet\")\n",
    "    # print(\"\\n\\n\\n\" + response_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
